{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ccac8768",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install kagglehub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e586a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Next Page Token = CfDJ8MM2ZkWST_dHsDXj-CCe3ENTqReSpnH0pJavmT1Z8P4jSqk2a05Z_7g6-z8Zl51rAvLmD2FxUmikNCdTTVS3ux0\n",
      "    id  ref                                            title                                        subtitle                                                                                                                                                                                                                         author               \n",
      "------  ---------------------------------------------  -------------------------------------------  -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------  -------------------  \n",
      "529704  google/functiongemma                           FunctionGemma                                FunctionGemma is a lightweight, open model from Google, built as a foundation for creating your own specialized function calling models.                                                                                         Google               \n",
      "539091  qwen-lm/qwen-image-layered                     Qwen Image Layered                           Qwen-Image-Layered, a model capable of decomposing an image into multiple RGBA layers                                                                                                                                            QwenLM               \n",
      "528480  wasupandceacar/physio-seg-public               physio-seg-public                                                                                                                                                                                                                                                             wasupandceacar       \n",
      "   986  metaresearch/dinov2                            DINO v2                                      Vision Transformer (ViT) model trained using the DINOv2 method.                                                                                                                                                                  Meta                 \n",
      "510647  ipythonx/vsd-model                             Vesuvius Surface Detection Model             Experimental models for vesuvius surface detection                                                                                                                                                                               Innat                \n",
      "322000  qwen-lm/qwen-3                                 Qwen 3                                       Qwen3 is the latest generation of large language models in Qwen series, offering a comprehensive suite of dense and mixture-of-experts (MoE) models.                                                                             QwenLM               \n",
      "  3301  google/gemma                                   Gemma                                        Gemma is a family of lightweight, open models built from the research and technology that Google used to create the Gemini models.                                                                                               Google               \n",
      "521710  shelterw/gpt                                   GPT                                                                                                                                                                                                                                                                           ShelterW             \n",
      "522039  mistral-ai/ministral-3                         Ministral 3                                  The Ministral 3 family is designed for edge deployment, capable of running on a wide range of hardware. Ministral 3 14B can even be deployed locally, capable of fitting in 24GB of VRAM in FP8, and less if further quantized.  Mistral AI           \n",
      "539167  loopassembly/akkadian-byt5-translator          akkadian-byt5-small-translator               Akkadian-to-English Neural Machine Translation (ByT5-Small Fine-tuned)                                                                                                                                                           Ashutosh Anand       \n",
      "534998  antonoof/dinobestmodel                         DinoBestmodel                                                                                                                                                                                                                                                                 Antonoof             \n",
      "504592  ravaghi/dinov2                                 DINOv2 | Scientific Image Forgery Detection                                                                                                                                                                                                                                   Mahdi Ravaghi        \n",
      "487624  gothamjocker/csiro                             CSIRO                                        Transformer Based Model Series in CSIRO Competition                                                                                                                                                                              Chika Komari         \n",
      "539310  google/gemini-3-flash-api                      Gemini 3 Flash API                           A new family of multimodal models from Google DeepMind                                                                                                                                                                           Google               \n",
      "540392  sarcasmos/lstm-gru-hybrid-attention-model      LSTM GRU Hybrid Attention Model              LSTM-GRU Hybrid Model for Sequence Learning Author: Sheikh Abdul Rehman                                                                                                                                                          Sheikh Abdul Rehman  \n",
      "422384  danielhanchen/gpt-oss-120b                     gpt-oss-120b                                                                                                                                                                                                                                                                  Unsloth AI           \n",
      "222398  google/gemma-3                                 Gemma 3                                      Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                                        Google               \n",
      "540799  jeanjean111/byt5-adafactor-comp-dataset-train  byt5 adafactor comp dataset train                                                                                                                                                                                                                                             Jean-Louis Roy       \n",
      "  3533  keras/gemma                                    Gemma                                        Keras implementation of the Gemma model. This Keras 3 implementation will run on JAX, TensorFlow and PyTorch.                                                                                                                    Keras                \n",
      " 76277  google/gemma-2                                 Gemma 2                                      Gemma is a family of lightweight, state-of-the-art open models from Google, built from the same research and technology used to create the Gemini models.                                                                        Google               \n"
     ]
    }
   ],
   "source": [
    "import kaggle\n",
    "from kaggle.api.kaggle_api_extended import KaggleApi\n",
    "api = KaggleApi()\n",
    "api.authenticate()\n",
    "api.model_list_cli()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c11801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets = [\n",
    "    \"catherinrevu/insightflow-saas-analytics-data\",\n",
    "    \"halaturkialotaibi/saas-business-metrics-customers-plans-and-revenue\",\n",
    "    \"lava18/google-play-store-apps\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3637878a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset URL: https://www.kaggle.com/datasets/catherinrevu/insightflow-saas-analytics-data\n",
      "Dataset URL: https://www.kaggle.com/datasets/halaturkialotaibi/saas-business-metrics-customers-plans-and-revenue\n",
      "Dataset URL: https://www.kaggle.com/datasets/lava18/google-play-store-apps\n"
     ]
    }
   ],
   "source": [
    "for d in datasets:\n",
    "    api.dataset_download_files(\n",
    "        d,\n",
    "        path=\"raw_data\",\n",
    "        unzip=True\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
