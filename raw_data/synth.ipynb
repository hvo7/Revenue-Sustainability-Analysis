{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "ced5ba0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install duckdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "fca94039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install torch-directml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b013224f",
   "metadata": {},
   "source": [
    "### This file is used to synthesize data that mimics the existing patterns of a dataset. For project purposes sake, we can synthesize data to more realistically represent real-world data. \n",
    "\n",
    "This currently only applies to the feature_usage.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "229fc6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb \n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "con = duckdb.connect()\n",
    "\n",
    "base_dir = Path(\"C:\\\\Users\\\\henry\\\\OneDrive\\\\Personal Career\\\\Personal Projects\\\\GitHub\\\\Revenue-Sustainability-Analysis\")\n",
    "data_dir = Path(base_dir / \"raw_data/Kaggle\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "1c11491f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_rows', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "0bce3412",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = con.execute(f\"\"\"\n",
    "    SELECT *\n",
    "    FROM '{data_dir}/ravenstack_feature_usage.csv'\n",
    "                 \"\"\").df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "b5b05c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Using device: privateuseone:0\n",
      "Tensor on AMD GPU: tensor([1., 1., 1.], device='privateuseone:0')\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_directml\n",
    "import pandas as pd\n",
    "import uuid\n",
    "from sdv.metadata import Metadata\n",
    "from sdv.single_table import GaussianCopulaSynthesizer\n",
    "from sdv.sampling import Condition\n",
    "\n",
    "# Check if DirectML is available\n",
    "if torch_directml.is_available():\n",
    "    device = torch_directml.device()\n",
    "    print(f\"Success! Using device: {device}\")\n",
    "    \n",
    "    # Create a tensor on your AMD GPU\n",
    "    x = torch.ones(3).to(device)\n",
    "    print(\"Tensor on AMD GPU:\", x)\n",
    "else:\n",
    "    print(\"DirectML not found. Check your installation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7c2fc06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sdv\\metadata\\single_table.py:835: UserWarning: There is an existing primary key 'usage_pk'. This key will be removed.\n",
      "  warnings.warn(\n",
      "c:\\Users\\henry\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sdv\\single_table\\base.py:134: UserWarning: We strongly recommend saving the metadata using 'save_to_json' for replicability in future SDV versions.\n",
      "  warnings.warn(\n",
      "Sampling conditions: 100%|██████████| 198/198 [00:00<00:00, 1376.62it/s]\n"
     ]
    }
   ],
   "source": [
    "RELEASE_TS = pd.Timestamp(\"2025-10-01\")\n",
    "INTRODUCED_FEATURE = \"feature_new_ai\"\n",
    "TOTAL_ROWS = 50000\n",
    "POST_RELEASE_LIFT = 3.0\n",
    "TABLE = \"usage_events\"\n",
    "\n",
    "df = df.copy()\n",
    "\n",
    "# types\n",
    "df[\"usage_date\"] = pd.to_datetime(df[\"usage_date\"], errors=\"coerce\")\n",
    "df[\"feature_name\"] = df[\"feature_name\"].replace(\"None\", pd.NA)\n",
    "df = df.dropna(subset=[\"feature_name\"])\n",
    "\n",
    "df[\"subscription_id\"] = df[\"subscription_id\"].astype(str)\n",
    "df[\"feature_name\"] = df[\"feature_name\"].astype(str)\n",
    "df[\"is_beta_feature\"] = df[\"is_beta_feature\"].astype(bool)\n",
    "\n",
    "for c in [\"usage_count\", \"usage_duration_secs\", \"error_count\"]:\n",
    "    df[c] = pd.to_numeric(df[c], errors=\"coerce\").fillna(0).astype(int)\n",
    "\n",
    "# release flag\n",
    "df[\"post_release\"] = (df[\"usage_date\"] >= RELEASE_TS)\n",
    "\n",
    "# ensure introduced feature exists\n",
    "if INTRODUCED_FEATURE not in set(df[\"feature_name\"].unique()):\n",
    "    seed_n = max(10, int(0.002 * len(df)))\n",
    "    seed = df.sample(seed_n, random_state=42).copy()\n",
    "    seed[\"feature_name\"] = INTRODUCED_FEATURE\n",
    "    seed[\"post_release\"] = True\n",
    "    seed[\"is_beta_feature\"] = False\n",
    "    df = pd.concat([df, seed], ignore_index=True)\n",
    "\n",
    "# CRITICAL: create guaranteed-unique PK AFTER all concatenations\n",
    "df[\"usage_pk\"] = [uuid.uuid4().hex for _ in range(len(df))]\n",
    "\n",
    "# metadata\n",
    "metadata = Metadata.detect_from_dataframe(data=df, table_name=TABLE)\n",
    "metadata.update_column(table_name=TABLE, column_name=\"usage_pk\", sdtype=\"id\")\n",
    "metadata.set_primary_key(table_name=TABLE, column_name=\"usage_pk\")\n",
    "metadata.update_column(table_name=TABLE, column_name=\"usage_date\", sdtype=\"datetime\")\n",
    "\n",
    "# fit\n",
    "synth = GaussianCopulaSynthesizer(metadata, enforce_min_max_values=True, enforce_rounding=True)\n",
    "synth.fit(df)\n",
    "\n",
    "# sample baseline\n",
    "syn_base = synth.sample(num_rows=TOTAL_ROWS)\n",
    "\n",
    "# oversample introduced feature post-release\n",
    "post_df = df[df[\"post_release\"] == True]\n",
    "post_share = len(post_df) / len(df) if len(df) else 0.5\n",
    "post_n = int(TOTAL_ROWS * post_share)\n",
    "\n",
    "base_feat_share_post = (post_df[\"feature_name\"] == INTRODUCED_FEATURE).mean() if len(post_df) else 0.0\n",
    "base_feat_n_post = int(post_n * base_feat_share_post)\n",
    "target_feat_n_post = int(base_feat_n_post * POST_RELEASE_LIFT)\n",
    "add_n = max(0, target_feat_n_post - base_feat_n_post)\n",
    "\n",
    "if add_n > 0:\n",
    "    cond = Condition({\"post_release\": True, \"feature_name\": INTRODUCED_FEATURE}, num_rows=add_n)\n",
    "    syn_lift = synth.sample_from_conditions([cond])\n",
    "    synthetic_df = pd.concat([syn_base, syn_lift], ignore_index=True)\n",
    "else:\n",
    "    synthetic_df = syn_base.copy()\n",
    "\n",
    "# final unique id for synthetic dataset\n",
    "synthetic_df[\"usage_id\"] = [f\"syn_usage_{i}\" for i in range(len(synthetic_df))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "0d2b6e91",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_base = df.copy()\n",
    "\n",
    "# Safety: drop missing or invalid feature names\n",
    "df_base[\"feature_name\"] = df_base[\"feature_name\"].replace(\"None\", pd.NA)\n",
    "df_base = df_base.dropna(subset=[\"feature_name\"])\n",
    "\n",
    "# ----------------------------\n",
    "# 1) Total number of subscriptions (denominator)\n",
    "# ----------------------------\n",
    "total_subs = df_base[\"subscription_id\"].nunique()\n",
    "\n",
    "# ----------------------------\n",
    "# 2) Aggregate usage at (feature, subscription) level\n",
    "#    This avoids power users dominating the metrics\n",
    "# ----------------------------\n",
    "feature_sub_agg = (\n",
    "    df_base\n",
    "    .groupby([\"feature_name\", \"subscription_id\"], as_index=False)\n",
    "    .agg(\n",
    "        total_usage_count=(\"usage_count\", \"sum\"),\n",
    "        total_usage_duration=(\"usage_duration_secs\", \"sum\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 3) Build the feature-level table\n",
    "# ----------------------------\n",
    "feature_baseline = (\n",
    "    feature_sub_agg\n",
    "    .groupby(\"feature_name\")\n",
    "    .agg(\n",
    "        subscriptions_used=(\"subscription_id\", \"nunique\"),\n",
    "        median_usage_count_per_sub=(\"total_usage_count\", \"median\"),\n",
    "        median_usage_duration_secs_per_sub=(\"total_usage_duration\", \"median\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 4) Add % of subscriptions used\n",
    "# ----------------------------\n",
    "feature_baseline[\"pct_subscriptions_used\"] = (\n",
    "    feature_baseline[\"subscriptions_used\"] / total_subs\n",
    ")\n",
    "\n",
    "# ----------------------------\n",
    "# 5) Sort for inspection (most widely used first)\n",
    "# ----------------------------\n",
    "feature_baseline = feature_baseline.sort_values(\n",
    "    by=\"pct_subscriptions_used\",\n",
    "    ascending=False\n",
    ")\n",
    "\n",
    "# Optional: make percentages readable\n",
    "feature_baseline[\"pct_subscriptions_used\"] = (\n",
    "    feature_baseline[\"pct_subscriptions_used\"] * 100\n",
    ").round(2)\n",
    "\n",
    "# Optional: round other metrics\n",
    "feature_baseline[\"median_usage_duration_secs_per_sub\"] = (\n",
    "    feature_baseline[\"median_usage_duration_secs_per_sub\"].round(0).astype(int)\n",
    ")\n",
    "\n",
    "feature_baseline.head(10)\n",
    "\n",
    "synthetic_df['usage_id'] = synthetic_df['usage_id'].str.replace('syn_', \"\", regex=False)\n",
    "synthetic_df['usage_pk'] = synthetic_df['usage_pk'].str.replace('sdv-',\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f86ca9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "synthetic_df.to_csv(data_dir / 'feature_usage.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b0898ce7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05918119173084718"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "percent_interacted = synthetic_df.loc[\n",
    "    synthetic_df['feature_name'] == 'feature_new_ai',\n",
    "    'subscription_id'\n",
    "].nunique() / synthetic_df['subscription_id'].nunique()\n",
    "\n",
    "percent_interacted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "4b00f83b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4934"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df['subscription_id'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "218d84c7",
   "metadata": {},
   "source": [
    "About 6% of subscriptions interacetd with the new feature 'feature_new_ai'. This is sufficient enough to be considered realistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e1fc524a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_dir / 'ravenstack_subscriptions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f25d67ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5000"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "49d3672c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], dtype=object)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "synthetic_df.loc[\n",
    "    ~synthetic_df['subscription_id'].isin(df['subscription_id']),\n",
    "    'subscription_id'\n",
    "].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5afafe7",
   "metadata": {},
   "source": [
    "I see that each subscription_id that is in synthetic appears at least once in the subscriptions.csv . Therefore, we can get link any subscription_id from feature_usage.csv to subcriptions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7186bd7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
