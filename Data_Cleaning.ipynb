{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d9f6c6b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import string\n",
    "import re\n",
    "\n",
    "base_dir = Path(\"C:\\\\Users\\\\henry\\\\OneDrive\\\\Personal Career\\\\Personal Projects\\\\GitHub\\\\Revenue-Sustainability-Analysis\")\n",
    "data_dir = base_dir / \"raw_data\" # raw_data contains kaggle data with data quality defects from messy package\n",
    "output_dir = base_dir / \"Dataset\" # Dataset contains cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d56d080e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_str_cols(df, exclude=[]):\n",
    "    cut = df[exclude].copy()\n",
    "    df = df.drop(columns=exclude)\n",
    "\n",
    "    for column in df.select_dtypes(include=[\"object\"]).columns:\n",
    "\n",
    "        # Remove punctuation\n",
    "        df[f\"{column}\"] = df[f\"{column}\"].str.replace(\n",
    "            f\"[{re.escape(string.punctuation)}]\", \n",
    "            \"\",\n",
    "            regex=True)\n",
    "        \n",
    "        df[f\"{column}\"] = df[f\"{column}\"].str.title() # Standardize Capitalization\n",
    "        df[f\"{column}\"] = df[f\"{column}\"].str.strip() # Remove leading and trailing spaces \n",
    "\n",
    "    \n",
    "    df = df.join(cut)\n",
    "\n",
    "    return df\n",
    "\n",
    "def clean_date_cols(df, date_cols: str | list[str], punct_keep: str | list[str] | None=None) -> pd.DataFrame:\n",
    "\n",
    "    # Exclude punctuation from being removed\n",
    "    if punct_keep is not None:\n",
    "        punctuation = \"\".join(set(string.punctuation) - set(punct_keep))   \n",
    "    else:\n",
    "        punctuation = string.punctuation\n",
    "\n",
    "    # If only 1 column is passed\n",
    "    if isinstance(date_cols, str):\n",
    "        df[f\"{date_cols}\"] = df[f\"{date_cols}\"].str.replace(\n",
    "                f\"[{re.escape(punctuation)}]\",\n",
    "                \"\",\n",
    "                regex=True\n",
    "            )\n",
    "    \n",
    "    # If multiple columns are passed\n",
    "    elif isinstance(date_cols, list):\n",
    "        for col in date_cols:\n",
    "\n",
    "            df[f\"{col}\"] = df[f\"{col}\"].str.replace(\n",
    "                f\"[{re.escape(punctuation)}]\",\n",
    "                \"\",\n",
    "                regex=True\n",
    "            )\n",
    "\n",
    "            df[f\"{col}\"] = df[f\"{col}\"].str.strip()\n",
    "\n",
    "    else:\n",
    "        raise TypeError(\"date_cols is neither a string nor list of strings\")\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f30afeec",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.max_rows\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8646cfb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5b2ce2d7",
   "metadata": {},
   "source": [
    "### Clean Accounts.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b741210d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir) # Ensure we are in the raw_data dir\n",
    "\n",
    "# df = pd.read_csv(\"accounts.csv\") \n",
    "\n",
    "# df = clean_str_cols(df, exclude=[\"created_at\"]) # Clean str columns\n",
    "\n",
    "# # Change floating cols to\n",
    "# df['account_id'] = df['account_id'].astype('Int64')\n",
    "# df['mrr'] = df['mrr'].astype('Int64')\n",
    "\n",
    "# # Save the cleaned accounts to Dataset dir\n",
    "# os.chdir(output_dir)\n",
    "# df.to_parquet(output_dir / \"accounts.parquet\", index=False)\n",
    "\n",
    "# # Switch back to raw_data for the next table cleaning\n",
    "# os.chdir(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "819346cd",
   "metadata": {},
   "source": [
    "### Clean customers.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "104db841",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"customers.csv\")\n",
    "\n",
    "# df['customer_id'] = df['customer_id'].astype('Int64')\n",
    "\n",
    "# df['signup_date'] = df['signup_date'].str.strip()\n",
    "\n",
    "# df['monthly_fee'] = df['monthly_fee'].astype('Int64')\n",
    "\n",
    "# df['acquisition_cost'] = df['acquisition_cost'].astype('Int64')\n",
    "\n",
    "# df['churn_date'] = df['churn_date'].str.strip()\n",
    "# df['churn_date'] = df['churn_date'].str.lower()\n",
    "\n",
    "# df.to_parquet(output_dir / \"customers.parquet\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c5a557",
   "metadata": {},
   "source": [
    "### Clean events.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "de1aaa1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)\n",
    "events = pd.read_csv(\"events.csv\")\n",
    "\n",
    "events['event_id'] = events['event_id'].astype('Int64')\n",
    "events['user_id'] = events['user_id'].astype('Int64')\n",
    "\n",
    "\n",
    "events = events.drop(columns='...6')\n",
    "\n",
    "events = clean_str_cols(events, exclude=['occurred_at'])\n",
    "\n",
    "events['occurred_at'] = events['occurred_at'].str.strip()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234f7fc2",
   "metadata": {},
   "source": [
    "### Clean experiments.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3a16a08d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir)\n",
    "\n",
    "# df = pd.read_csv(\"experiments.csv\")\n",
    "\n",
    "# # df.head(5)\n",
    "\n",
    "# # df.dtypes\n",
    "\n",
    "# df['experiment_id'] = df['experiment_id'].astype(\"Int64\")\n",
    "\n",
    "# df = clean_str_cols(df, exclude=['start_date', 'end_date'])\n",
    "\n",
    "# df = clean_date_cols(df, date_cols=['start_date', 'end_date'])\n",
    "\n",
    "# df.to_parquet(output_dir / \"experiments.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aad82f0",
   "metadata": {},
   "source": [
    "### Clean googleplaystore_user_reviews.csv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66aa7feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir)\n",
    "\n",
    "# df = pd.read_csv(\"googleplaystore_user_reviews.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28090448",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # pd.options.display.float_format = \"{:.2f}\".format\n",
    "\n",
    "# # df.head()\n",
    "\n",
    "# # df.dtypes\n",
    "\n",
    "# df = clean_str_cols(df)\n",
    "\n",
    "# df['Sentiment'] = (df['Sentiment'].str.lower()).astype('str')\n",
    "\n",
    "# df['Sentiment_Polarity'] = df['Sentiment_Polarity'] \\\n",
    "# .astype(\"str\") \\\n",
    "# .where(df['Sentiment_Polarity'].notna()) \\\n",
    "# .str.replace(r\"^0\", \"0.\", regex=True) \\\n",
    "# .astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9e34eb38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Sentiment_Subjectivity'] = df['Sentiment_Subjectivity'] \\\n",
    "# .astype(\"str\") \\\n",
    "# .where(df['Sentiment_Polarity'].notna()) \\\n",
    "# .str.replace(r\"^0\", \"0.\", regex=True) \\\n",
    "# .astype(\"float\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "04d3c981",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = df.drop(columns=['App', 'Translated_Review'])\n",
    "\n",
    "# df.to_parquet(output_dir / \"googleplaystore_user_reviews.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e982905",
   "metadata": {},
   "source": [
    "### Clean revenue.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "829c5938",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "<>:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "C:\\Users\\henry\\AppData\\Local\\Temp\\ipykernel_26104\\2030961580.py:25: SyntaxWarning: invalid escape sequence '\\d'\n",
      "  .str.extract(\"(\\d{4})(\\d{2})\") \\\n"
     ]
    }
   ],
   "source": [
    "os.chdir(data_dir)\n",
    "\n",
    "revenue = pd.read_csv(\"revenue.csv\")\n",
    "\n",
    "revenue['customer_id'] = revenue['customer_id'].astype(\"Int64\")\n",
    "revenue['monthly_fee'] = revenue['monthly_fee'].astype(\"Int64\")\n",
    "\n",
    "revenue = clean_str_cols(revenue, exclude=['subscription_id', 'month'])\n",
    "\n",
    "revenue['revenue_type'] = revenue['revenue_type'].str.lower()\n",
    "\n",
    "# Format Month\n",
    "revenue = clean_date_cols(revenue, ['month'], \"-\")\n",
    "revenue['month'] = revenue['month'].replace(r\"--+\", \"-\", regex=True).str.lower()\n",
    "\n",
    "\n",
    "\n",
    "# Format subscription_id\n",
    "revenue = clean_date_cols(revenue, 'subscription_id')\n",
    "\n",
    "revenue['subscription_id'] = revenue['subscription_id'].str.extract(r\"(S)(\\d{4})(\\d{6})\") \\\n",
    "                    .apply(lambda x: f\"{x[0]}-{x[1]}-{x[2]}\" if x.notna().all() else None, axis=1)\n",
    "\n",
    "revenue['month'] = revenue['month'].str.replace(\"-\",\"\") \\\n",
    "           .str.extract(\"(\\d{4})(\\d{2})\") \\\n",
    "           .apply(lambda x: f\"{x[0]}-{x[1]}\" if x.notna().all() else None, axis=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14d7d736",
   "metadata": {},
   "source": [
    "### Clean subscriptions.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2e51dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(data_dir)\n",
    "\n",
    "subscriptions = pd.read_csv(\"subscriptions.csv\")\n",
    "\n",
    "subscriptions.head()\n",
    "\n",
    "subscriptions['subscription_id'] = (subscriptions['subscription_id'].str.upper()).str.replace(r\"--+\", \"\", regex=True)\n",
    "\n",
    "subscriptions['subscription_id'] = subscriptions['subscription_id'].str.extract(r\"(S-\\d{4}).*(\\d{6})\") \\\n",
    "                    .apply(lambda x: f\"{x[0]}-{x[1]}\" if x.notna().all() else None, axis=1)\n",
    "\n",
    "subscriptions['customer_id'] = subscriptions['customer_id'].astype(\"Int64\")\n",
    "\n",
    "subscriptions = clean_date_cols(subscriptions, 'month')\n",
    "\n",
    "subscriptions['month'] = subscriptions['month'].str.extract(r\"(\\d{4})(\\d{2})\") \\\n",
    "                .apply(lambda x: f\"{x[0]}-{x[1]}\" if x.notna().all() else None,axis=1)\n",
    "\n",
    "subscriptions['monthly_fee'] = subscriptions['monthly_fee'].astype(\"Int64\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2309d19",
   "metadata": {},
   "source": [
    "### Clean users.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c69237d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir)\n",
    "\n",
    "# df = pd.read_csv(\"users.csv\")\n",
    "\n",
    "# df['user_id'] = df['user_id'].astype(\"Int64\")\n",
    "\n",
    "# df['account_id'] = df['account_id'].astype(\"Int64\")\n",
    "\n",
    "# # Keep email messy. Its a bigger problem, but not necessary to fix currently\n",
    "\n",
    "# # xd = df.copy()\n",
    "\n",
    "# # xd['email'] = (df['email'].str.lower()).str.strip()\n",
    "# # xd = clean_date_cols(xd, 'email', '.')\n",
    "\n",
    "# # s = xd['email'].dropna()\n",
    "# # s = s.str.replace(\".\",'', regex=False)\n",
    "\n",
    "# # acct = s.str.extract(r'([a-z]+)(acct\\d+io)')\n",
    "\n",
    "# df = clean_date_cols(df, ['role', 'country'])\n",
    "\n",
    "# df['role'] = df['role'].str.lower()\n",
    "# df['country'] = df['country'].str.upper()\n",
    "\n",
    "# df['is_active'] = df['country'].astype('bool')\n",
    "\n",
    "# df.to_parquet(output_dir / \"users.parquet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63d134d5",
   "metadata": {},
   "source": [
    "### Clean variants.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8f318b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir)\n",
    "\n",
    "# df = pd.read_csv('variants.csv')\n",
    "\n",
    "# df = clean_date_cols(df, ['variant_key', 'name', 'description', 'creative_type'])\n",
    "\n",
    "# df['name'] = df['name'].str.title()\n",
    "# df['variant_key'] = df['variant_key'].str.lower()\n",
    "# df['creative_type'] = df['creative_type'].str.lower()\n",
    "\n",
    "# df['variant_id'] = df['variant_id'].astype('Int64') \n",
    "\n",
    "# df['is_control'] = df['is_control'].astype('bool')\n",
    "\n",
    "# df.to_parquet(output_dir / 'variants.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65fa2a75",
   "metadata": {},
   "source": [
    "### Clean variant_exposures.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2794e517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# os.chdir(data_dir)\n",
    "\n",
    "# df = pd.read_csv('variant_exposures.csv')\n",
    "\n",
    "# # df.head()\n",
    "\n",
    "# df['exposure_id'] = df['exposure_id'].astype('Int64')\n",
    "# df['experiment_id'] = df['experiment_id'].astype('Int64')\n",
    "# df['variant_id'] = df['variant_id'].astype('Int64')\n",
    "# df['user_id'] = df['user_id'].astype('Int64')\n",
    "# df['clicks'] = df['clicks'].astype('Int64')\n",
    "# df['conversions'] = df['conversions'].astype('Int64')\n",
    "\n",
    "# df = df.drop(columns='...9')\n",
    "\n",
    "# df.to_parquet(output_dir / 'variant_exposures.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f2cad3",
   "metadata": {},
   "source": [
    "### Change dates\n",
    "For realistic purposes, we will randomly assign some rows to 2025-11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4347dd07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "revenue: 2024-01-01 00:00:00 2025-11-01 00:00:00\n",
      "events: 2025-05-20 18:51:40 2025-11-30 06:46:56\n",
      "subscriptions: 2024-01-01 00:00:00 2025-11-01 00:00:00\n"
     ]
    }
   ],
   "source": [
    "def force_some_rows_to_nov_2025(\n",
    "    df: pd.DataFrame,\n",
    "    date_col: str,\n",
    "    pct: float = 0.05,\n",
    "    seed: int = 42\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Randomly selects ~pct of rows and sets date_col to November 2025.\n",
    "    Preserves day when possible (clamped to 30) and time-of-day for timestamps.\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Ensure datetime\n",
    "    out[date_col] = pd.to_datetime(out[date_col], errors=\"coerce\")\n",
    "\n",
    "    # Random mask\n",
    "    rng = np.random.default_rng(seed)\n",
    "    mask = rng.random(len(out)) < pct\n",
    "\n",
    "    # Extract components safely\n",
    "    day = out.loc[mask, date_col].dt.day.clip(upper=30)\n",
    "    hour = out.loc[mask, date_col].dt.hour.fillna(0).astype(int)\n",
    "    minute = out.loc[mask, date_col].dt.minute.fillna(0).astype(int)\n",
    "    second = out.loc[mask, date_col].dt.second.fillna(0).astype(int)\n",
    "\n",
    "    # Assign new dates\n",
    "    out.loc[mask, date_col] = pd.to_datetime(\n",
    "        {\n",
    "            \"year\": 2025,\n",
    "            \"month\": 11,\n",
    "            \"day\": day,\n",
    "            \"hour\": hour,\n",
    "            \"minute\": minute,\n",
    "            \"second\": second,\n",
    "        },\n",
    "        errors=\"coerce\",\n",
    "    )\n",
    "\n",
    "    return out\n",
    "\n",
    "# Apply to your tables\n",
    "revenue = force_some_rows_to_nov_2025(\n",
    "    revenue,\n",
    "    date_col=\"month\",\n",
    "    pct=0.05,\n",
    "    seed=1\n",
    ")\n",
    "\n",
    "events = force_some_rows_to_nov_2025(\n",
    "    events,\n",
    "    date_col=\"occurred_at\",\n",
    "    pct=0.05,\n",
    "    seed=2\n",
    ")\n",
    "\n",
    "subscriptions = force_some_rows_to_nov_2025(\n",
    "    subscriptions,\n",
    "    date_col=\"month\",\n",
    "    pct=0.05,\n",
    "    seed=3\n",
    ")\n",
    "\n",
    "# Save to parquet\n",
    "revenue.to_parquet(output_dir / \"revenue.parquet\")\n",
    "events.to_parquet(output_dir / \"events.parquet\", index=False)\n",
    "subscriptions.to_parquet(output_dir / \"subscriptions.parquet\")\n",
    "\n",
    "\n",
    "# Verify min/max dates\n",
    "\n",
    "print(\"revenue:\", revenue[\"month\"].min(), revenue[\"month\"].max())\n",
    "print(\"events:\", events[\"occurred_at\"].min(), events[\"occurred_at\"].max())\n",
    "print(\"subscriptions:\", subscriptions[\"month\"].min(), subscriptions[\"month\"].max())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
